{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0f4f248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ffda98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853021d8",
   "metadata": {},
   "source": [
    "# Acquire transcript data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ecf2fd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11936, 4, 15), (11936,))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import preprocess_transcript\n",
    "(X,y),vocab = preprocess_transcript()\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b417f74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10145, 4, 15), (10145,), (1791, 4, 15), (1791,))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X0, X1, Y0, Y1 = train_test_split(X, y, test_size=0.15,random_state=1)\n",
    "X0.shape, Y0.shape, X1.shape, Y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b1537c",
   "metadata": {},
   "source": [
    "# Benchmark RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fa570aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_39 (Embedding)    multiple                  320000    \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       multiple                  0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              multiple                  98816     \n",
      "                                                                 \n",
      " dense_91 (Dense)            multiple                  645000    \n",
      "                                                                 \n",
      " dense_92 (Dense)            multiple                  10002     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,073,818\n",
      "Trainable params: 1,073,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from rnn import RNN,train_RNN\n",
    "%aimport rnn\n",
    "model = RNN(len(vocab))\n",
    "model.build(X0.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e4dbf4b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnn_train_loss,rnn_train_acc =[],[]\n",
    "rnn_val_loss,rnn_val_acc =[],[]\n",
    "\n",
    "for i in range(5):\n",
    "    model = RNN(len(vocab))\n",
    "    history = train_RNN(model, X0, Y0, X1, Y1)\n",
    "    rnn_train_loss.append(min(history.history['loss']))\n",
    "    rnn_train_acc.append(max(history.history['sparse_categorical_accuracy']))\n",
    "    rnn_val_loss.append(min(history.history['val_loss']))\n",
    "    rnn_val_acc.append(max(history.history['val_sparse_categorical_accuracy']))\n",
    "    if i == 4: model.save('../models/rnn')\n",
    "    del model\n",
    "    gc.collect()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f0cad88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23932151794433593, 0.895633316040039)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_train_loss),np.mean(rnn_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0e38cfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6593041896820069, 0.6135120034217835)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_val_loss),np.mean(rnn_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea361f88",
   "metadata": {},
   "source": [
    "# Baseline Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d8ca1082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_encoder_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_45 (Embedding)    multiple                  320000    \n",
      "                                                                 \n",
      " transformer_block_rank_four  multiple                 16576     \n",
      " _26 (TransformerBlockRankFo                                     \n",
      " ur)                                                             \n",
      "                                                                 \n",
      " dense_104 (Dense)           multiple                  7682      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344,258\n",
      "Trainable params: 344,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformer_encoder import TransformerEncoder,train_TransformerEncoder\n",
    "%aimport transformer_encoder\n",
    "embedding_size = 64\n",
    "window = 15\n",
    "model = TransformerEncoder(len(vocab),embedding_size,window)\n",
    "model.build(X0.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c7a51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_train_loss,transformer_train_acc =[],[]\n",
    "transformer_val_loss,transformer_val_acc =[],[]\n",
    "for i in range(5):\n",
    "    model = TransformerEncoder(len(vocab),embedding_size,window)\n",
    "    history = train_TransformerEncoder(model, X0, Y0, X1, Y1)\n",
    "    transformer_train_loss.append(min(history.history['loss']))\n",
    "    transformer_train_acc.append(max(history.history['sparse_categorical_accuracy']))\n",
    "    transformer_val_loss.append(min(history.history['val_loss']))\n",
    "    transformer_val_acc.append(max(history.history['val_sparse_categorical_accuracy']))\n",
    "    if i == 4: model.save('../models/transformer')\n",
    "    del model\n",
    "    gc.collect()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cacdde31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2727239906787872, 0.8881419539451599)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(transformer_train_loss),np.mean(transformer_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "94feb761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.718769109249115, 0.5834729194641113)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(transformer_val_loss),np.mean(transformer_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5925b",
   "metadata": {},
   "source": [
    "# Augmented model Transcript w. statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eda5c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import preprocess_transcript_statement\n",
    "%aimport train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "df84ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, vocab = preprocess_transcript_statement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0b6f0dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10145, 804, 15), (10145,), (1791, 804, 15), (1791,))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0, X1, Y0, Y1 = train_test_split(X, y, test_size=0.15,random_state=1)\n",
    "X0.shape, Y0.shape, X1.shape, Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "aaf701e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_encoder_statement_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_51 (Embedding)    multiple                  368576    \n",
      "                                                                 \n",
      " transformer_block_rank_four  multiple                 16576     \n",
      " _32 (TransformerBlockRankFo                                     \n",
      " ur)                                                             \n",
      "                                                                 \n",
      " transformer_block_rank_four  multiple                 16576     \n",
      " _33 (TransformerBlockRankFo                                     \n",
      " ur)                                                             \n",
      "                                                                 \n",
      " dense_117 (Dense)           multiple                  1543682   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,945,410\n",
      "Trainable params: 1,945,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformer_encoder import TransformerEncoderStatement,train_TransformerEncoderStatement\n",
    "%aimport transformer_encoder\n",
    "embedding_size = 64\n",
    "window = 15\n",
    "model = TransformerEncoderStatement(len(vocab),embedding_size,window)\n",
    "model.build(X0.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2044f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_s_train_loss,transformer_s_train_acc =[],[]\n",
    "transformer_s_val_loss,transformer_s_val_acc =[],[]\n",
    "for i in range(5):\n",
    "    model = TransformerEncoderStatement(len(vocab),embedding_size,window)\n",
    "    history = train_TransformerEncoderStatement(model, X0, Y0, X1, Y1)\n",
    "    transformer_s_train_loss.append(min(history.history['loss']))\n",
    "    transformer_s_train_acc.append(max(history.history['sparse_categorical_accuracy']))\n",
    "    transformer_s_val_loss.append(min(history.history['val_loss']))\n",
    "    transformer_s_val_acc.append(max(history.history['val_sparse_categorical_accuracy']))\n",
    "    if i == 4: model.save('../models/transformer_statement')\n",
    "    del model\n",
    "    gc.collect()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0214eed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8431342601776124, 0.6859930992126465)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(transformer_s_train_loss),np.mean(transformer_s_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "695b43a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4995854139328002, 0.7134561777114868)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(transformer_s_val_loss),np.mean(transformer_s_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b80c7",
   "metadata": {},
   "source": [
    "# Augmented model Transcript w. statement & tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f9b3365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, vocab = preprocess_transcript_statement(add_tone=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b739e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10145, 822, 15), (10145,), (1791, 822, 15), (1791,))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0, X1, Y0, Y1 = train_test_split(X, y, test_size=0.15,random_state=1)\n",
    "X0.shape, Y0.shape, X1.shape, Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "73f01ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_encoder_statement_tone_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_57 (Embedding)    multiple                  368576    \n",
      "                                                                 \n",
      " transformer_block_rank_four  multiple                 16576     \n",
      " _44 (TransformerBlockRankFo                                     \n",
      " ur)                                                             \n",
      "                                                                 \n",
      " transformer_block_rank_four  multiple                 16576     \n",
      " _45 (TransformerBlockRankFo                                     \n",
      " ur)                                                             \n",
      "                                                                 \n",
      " transformer_block_rank_thre  multiple                 945       \n",
      " e_1 (TransformerBlockRankTh                                     \n",
      " ree)                                                            \n",
      "                                                                 \n",
      " dense_136 (Dense)           multiple                  1544222   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,946,895\n",
      "Trainable params: 1,946,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformer_encoder import TransformerEncoderStatementTone,train_TransformerEncoderStatementTone\n",
    "%aimport transformer_encoder\n",
    "embedding_size = 64\n",
    "window = 15\n",
    "model = TransformerEncoderStatementTone(len(vocab),embedding_size,window)\n",
    "model.build(X0.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0b2ae3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_st_train_loss,transformer_st_train_acc =[],[]\n",
    "transformer_st_val_loss,transformer_st_val_acc =[],[]\n",
    "for i in range(5):\n",
    "    model = TransformerEncoderStatement(len(vocab),embedding_size,window)\n",
    "    history = train_TransformerEncoderStatement(model, X0, Y0, X1, Y1)\n",
    "    transformer_st_train_loss.append(min(history.history['loss']))\n",
    "    transformer_st_train_acc.append(max(history.history['sparse_categorical_accuracy']))\n",
    "    transformer_st_val_loss.append(min(history.history['val_loss']))\n",
    "    transformer_st_val_acc.append(max(history.history['val_sparse_categorical_accuracy']))\n",
    "    if i == 0: \n",
    "        model.save('../models/transformer_statement_tone')\n",
    "        break\n",
    "    del model\n",
    "    gc.collect()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "94262ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8523714542388916, 0.6858550906181335)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(transformer_st_train_loss),np.mean(transformer_st_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3748b731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0373454093933105, 0.7185929417610168)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(transformer_st_loss),np.mean(transformer_st_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34154f1a",
   "metadata": {},
   "source": [
    "# Policy words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3189af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone = pd.read_csv('../input/processed/tones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "695a4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, vocabulary, statement_dict = preprocess_transcript_statement(add_tone=True,return_statement_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "67d3cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "18087c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['improv', 'foster', 'increas', 'moder', 'slow', 'weak', 'condit', 'anticip', 'believ']\n",
    "tone_05_04_22 = np.array(tone[tone['date']=='2022-05-04'].agg({'sad': 'mean', 'angry': 'mean', 'neutral': 'mean', 'happy': 'mean', 'disgust': 'mean', 'fearful': 'mean'}))\n",
    "statement_05_04_22 = statement_dict[datetime.datetime(2022, 5, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "48b89cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improv\n",
      "tf.Tensor([[0.80526406 0.19473594]], shape=(1, 2), dtype=float32)\n",
      "foster\n",
      "tf.Tensor([[0.81596005 0.18403992]], shape=(1, 2), dtype=float32)\n",
      "increas\n",
      "tf.Tensor([[0.81397444 0.18602556]], shape=(1, 2), dtype=float32)\n",
      "moder\n",
      "tf.Tensor([[0.8111978  0.18880214]], shape=(1, 2), dtype=float32)\n",
      "slow\n",
      "tf.Tensor([[0.8099522  0.19004774]], shape=(1, 2), dtype=float32)\n",
      "weak\n",
      "tf.Tensor([[0.8053697  0.19463035]], shape=(1, 2), dtype=float32)\n",
      "condit\n",
      "tf.Tensor([[0.80888265 0.19111733]], shape=(1, 2), dtype=float32)\n",
      "anticip\n",
      "tf.Tensor([[0.80831516 0.19168483]], shape=(1, 2), dtype=float32)\n",
      "believ\n",
      "tf.Tensor([[0.7987827  0.20121737]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 4620 is index for [QUIET]\n",
    "for w in words:\n",
    "    word_test = np.array( [4620 for i in range(59)]+[vocabulary[w]])\n",
    "    np.random.shuffle(word_test)\n",
    "    word_test = word_test.reshape(1, 4, 15)\n",
    "    statement_test = np.repeat(statement_05_04_22, 15)\n",
    "    statement_test = np.reshape(statement_test, (1, 800, 15))\n",
    "    tone_test = np.transpose(np.tile(tone_05_04_22, (15,1,1)),[1,2,0])\n",
    "    tone_test = np.repeat(tone_test, 3, axis=1)\n",
    "    D_test = np.concatenate([word_test, statement_test, tone_test], axis=1)\n",
    "    print(w)\n",
    "    print(model(D_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
